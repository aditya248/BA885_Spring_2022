{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unsupervised.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "u9glM401LbVG",
        "ygU64a1Vv5MZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unsupervised learning\n",
        "\n",
        "We will look at an example covered in \"Hands-on Unsupervised Learning Using Python\" by Ankur A. Patel. The accompanying material for the book can be found [here](https://github.com/aapatel09/handson-unsupervised-learning)."
      ],
      "metadata": {
        "id": "TooOfQIadhoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset from s3\n",
        "!pip install awscli\n",
        "!aws s3 cp s3://handson-unsupervised-learning/datasets/credit_card_data credit_card_data --recursive --no-sign-request"
      ],
      "metadata": {
        "id": "8PdbcRXJkOZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UTd2McdVdcVd"
      },
      "outputs": [],
      "source": [
        "import os, time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the data\n",
        "\n",
        "We will use a dataset containing credit card transactions from the book's accompanying material."
      ],
      "metadata": {
        "id": "XDit4NZIf5d2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('./credit_card_data/credit_card.csv')\n",
        "data.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "o2eq5J0OjkCE",
        "outputId": "e7d991bf-d2fd-46fb-f5ab-5131185ceb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "\n",
              "[2 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-888a68d8-63a2-45fb-bbea-328c1f4aa0bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-888a68d8-63a2-45fb-bbea-328c1f4aa0bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-888a68d8-63a2-45fb-bbea-328c1f4aa0bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-888a68d8-63a2-45fb-bbea-328c1f4aa0bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the samples and labels.\n",
        "# We choose the class column as our labels which classifies transactions\n",
        "# as valid (0) or fraudulent (1).\n",
        "\n",
        "samples = data.copy().drop(['Class','Time'],axis=1)\n",
        "labels = data['Class'].copy()\n",
        "\n",
        "# Split the data into train and test sets\n",
        "\n",
        "train_samples, test_samples, train_labels, test_labels = train_test_split(\n",
        "    samples, labels, test_size = 0.33, random_state=2022, stratify = labels\n",
        ")\n",
        "\n",
        "# Print out the shape of the train and test data\n",
        "\n",
        "print('train samples: {}'.format(train_samples.shape))\n",
        "print('(valid, fraud) = ({},{})'.format(\n",
        "    (train_labels==0).sum(),(train_labels==1).sum()\n",
        "))\n",
        "\n",
        "print('test samples: {}'.format(test_samples.shape))\n",
        "print('(valid, fraud) = ({},{})'.format(\n",
        "    (test_labels==0).sum(),(test_labels==1).sum()\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi81oCORlAW-",
        "outputId": "2172fd2f-a018-4223-de0a-0b9692423a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples: (190820, 29)\n",
            "(valid, fraud) = (190490,330)\n",
            "test samples: (93987, 29)\n",
            "(valid, fraud) = (93825,162)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_means = samples.mean()\n",
        "t_stds = samples.std()"
      ],
      "metadata": {
        "id": "GSoPi3vL7OMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "\n",
        "train_samples = (train_samples-t_means)/t_stds\n",
        "test_samples = (test_samples-t_means)/t_stds"
      ],
      "metadata": {
        "id": "qmzSdeg-tYql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversample the fraudulent transactions\n",
        "\n",
        "osp = 64\n",
        "osr = 0.2\n",
        "\n",
        "train_os_samples = train_samples.copy()\n",
        "train_os_labels = train_labels.copy()\n",
        "\n",
        "train_os_samples = train_os_samples.append(\n",
        "    [train_os_samples[train_os_labels==1].sample(frac=0.2)]*osp,\n",
        "    ignore_index = False\n",
        ")\n",
        "\n",
        "train_os_labels = train_os_labels.append(\n",
        "    [train_os_labels[train_os_labels==1].sample(frac=0.2)]*osp,\n",
        "    ignore_index = False\n",
        ")"
      ],
      "metadata": {
        "id": "80v2CS_4ybN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_os_samples.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH42GQTx0e-B",
        "outputId": "b1e4b8e5-571c-432c-c2a6-430c0b6b2e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(195044, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_os_samples, train_os_labels = shuffle(train_os_samples, train_os_labels)"
      ],
      "metadata": {
        "id": "t0GC58MX05HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model"
      ],
      "metadata": {
        "id": "zQCEBMVOri5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = keras.Sequential([\n",
        "    layers.Input(shape=(29,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "metric = ['binary_accuracy',\n",
        "           keras.metrics.FalseNegatives(name='fn'),\n",
        "           keras.metrics.FalsePositives(name='fp'),]\n",
        "baseline_model.compile(optimizer='adam',\n",
        "                       loss='binary_crossentropy',\n",
        "                       metrics=metric)"
      ],
      "metadata": {
        "id": "4cenHCadm1Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model.fit(train_os_samples, train_os_labels,\n",
        "                   batch_size = 64, epochs=2,\n",
        "                   validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SyNlO3-snNy",
        "outputId": "d3677127-c7ec-4e5e-b98d-a43944e98210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "2439/2439 [==============================] - 6s 2ms/step - loss: 0.0053 - binary_accuracy: 0.9992 - fn: 61.0000 - fp: 62.0000 - val_loss: 0.0037 - val_binary_accuracy: 0.9995 - val_fn: 9.0000 - val_fp: 10.0000\n",
            "Epoch 2/2\n",
            "2439/2439 [==============================] - 6s 2ms/step - loss: 0.0048 - binary_accuracy: 0.9993 - fn: 54.0000 - fp: 63.0000 - val_loss: 0.0032 - val_binary_accuracy: 0.9994 - val_fn: 6.0000 - val_fp: 17.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f06804c4490>"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_eval = baseline_model.evaluate(test_samples, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6emuBj7osqD5",
        "outputId": "632a42fa-51c8-4c21-f3eb-ac67e2e902c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2938/2938 [==============================] - 5s 2ms/step - loss: 0.0045 - binary_accuracy: 0.9993 - fn: 31.0000 - fp: 39.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model.evaluate(test_samples[test_labels==1], test_labels[test_labels==1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEIk8uWPD7SF",
        "outputId": "20228b0e-c4cb-40b5-d16e-acbc4fb112e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 1.5529 - binary_accuracy: 0.8086 - fn: 31.0000 - fp: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5529146194458008, 0.8086419701576233, 31.0, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_fn = int(baseline_eval[2])\n",
        "baseline_fp = int(baseline_eval[3])\n",
        "baseline_tn = (test_labels==0).sum()\n",
        "baseline_tp = (test_labels==1).sum()\n",
        "\n",
        "baseline_cm = np.array([[baseline_tp - baseline_fn, baseline_fn], \n",
        "                        [baseline_fp, baseline_tn - baseline_fp]])\n",
        "\n",
        "baseline_cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssVwKoI7EWeP",
        "outputId": "556b34f7-e1fd-4e9d-f14b-2194c7ee69e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  131,    31],\n",
              "       [   39, 93786]])"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy of a constant model which classifies all transactions as valid\n",
        "\n",
        "1-162/93987"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4_XJvlJv6n8",
        "outputId": "617b0e8b-0e1a-4b37-dfb7-e6bff77c3dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9982763573685722"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unsupervised model\n",
        "\n",
        "The key idea behind unsupervised learning for fraud/anomaly detection is to first train a generative model. Since the data is so unbalanced, the generative model will mostly learn to generate valid transactions. Fraudulent/anomalous transaction will thus be generated poorly marking them as fradulent."
      ],
      "metadata": {
        "id": "ER0pbU0jwf00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fd = keras.Sequential([\n",
        "    layers.Input(shape=(29,)),\n",
        "    layers.Dense(128, activity_regularizer=keras.regularizers.l1(10e-5)),\n",
        "    layers.LeakyReLU(alpha=0.2),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(32),\n",
        "    layers.LeakyReLU(alpha=0.2),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(128, activity_regularizer=keras.regularizers.l1(10e-5)),\n",
        "    layers.LeakyReLU(alpha=0.2),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(29)\n",
        "])\n",
        "\n",
        "model_fd.compile(optimizer='adam',\n",
        "                 loss='mse',\n",
        "                 metrics='accuracy')"
      ],
      "metadata": {
        "id": "0WGzaYqZwA7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fd.fit(train_os_samples, train_os_samples,\n",
        "             batch_size = 64, epochs = 32,\n",
        "             validation_split=0.2)"
      ],
      "metadata": {
        "id": "R7ej_L_O4BSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate reconstruction error\n",
        "\n",
        "def anomaly_scores(sample, reconstruction):\n",
        "    loss = np.sum((np.array(sample) - \n",
        "                   np.array(reconstruction))**2, axis=1)\n",
        "    loss = pd.Series(data=loss,index=sample.index)\n",
        "    loss = (loss-np.min(loss))/(np.max(loss)-np.min(loss))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "xkQCgBvv5ZaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_scores = anomaly_scores(test_samples, model_fd.predict(test_samples))"
      ],
      "metadata": {
        "id": "ZcKhWOzK6Bg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.03\n",
        "tn = (test_labels==0).sum()\n",
        "tp = (test_labels==1).sum()\n",
        "fn = (test_scores[test_labels==1]<=threshold).sum()\n",
        "fp = (test_scores[test_labels==0]>threshold).sum()\n",
        "cm = np.array([[tp - fn, fn], [fp, tn - fp]])\n",
        "\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBAY3sz48Wci",
        "outputId": "66bca450-704a-42dd-a11f-2f5352cd2bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   29,   133],\n",
              "       [  197, 93628]])"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "\n",
        "(tp + tn - fp - fn)/(tp + tn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz_N7bc7939a",
        "outputId": "8f6de3af-94df-48fd-c5b6-db3b3acdc948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9964888761211657"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using GANs"
      ],
      "metadata": {
        "id": "_a7_OM6vJW2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GAN model class"
      ],
      "metadata": {
        "id": "u9glM401LbVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN model class\n",
        "\n",
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        # The model simultaneously optimizes the generator and the discriminator.\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_samples):\n",
        "        batch_size = tf.shape(real_samples)[0]\n",
        "        # Generate random latent vectors used by the generator.\n",
        "        random_latent_vectors = tf.random.normal(\n",
        "            shape=(batch_size, self.latent_dim))\n",
        "        # Generator feedforward\n",
        "        generated_samples = self.generator(random_latent_vectors)\n",
        "        # Mix the real and fake samples.\n",
        "        combined_samples = tf.concat([generated_samples, \n",
        "                                      tf.cast(real_samples, tf.float32)], axis=0)\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))],\n",
        "            axis=0\n",
        "        )\n",
        "        # Introduce randomness which helps with training\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Discriminator feedforward\n",
        "            predictions = self.discriminator(combined_samples)\n",
        "            # Compute loss function with true labels.\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        # Update discriminator weights.\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        random_latent_vectors = tf.random.normal(\n",
        "            shape=(batch_size, self.latent_dim))\n",
        "        \n",
        "        # Pretend that the data generated below is real.\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(\n",
        "                self.generator(random_latent_vectors))\n",
        "            # Compute loss function with misleading labels.\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        # Update generator weights.\n",
        "        self.g_optimizer.apply_gradients(\n",
        "            zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\"d_loss\": self.d_loss_metric.result(),\n",
        "                \"g_loss\": self.g_loss_metric.result()}"
      ],
      "metadata": {
        "id": "_uhznFyjLaF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GAN model"
      ],
      "metadata": {
        "id": "8ai_7kuZLiMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN discriminator\n",
        "\n",
        "discriminator = keras.Sequential(\n",
        "    [layers.Input(shape=(29,)),\n",
        "     #...\n",
        "     layers.Dense(1, activation=\"sigmoid\"),],\n",
        "     name=\"discriminator\",)"
      ],
      "metadata": {
        "id": "9Y_pGAQ_L41T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN generator\n",
        "\n",
        "latent_dim = 16\n",
        "\n",
        "generator = keras.Sequential(\n",
        "    [layers.Input(shape=(latent_dim,)),\n",
        "     # ...\n",
        "     layers.Dense(29),],\n",
        "     name='generator',)"
      ],
      "metadata": {
        "id": "cdsfQ36WBNXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss_fn=keras.losses.MeanSquaredError(),\n",
        ")"
      ],
      "metadata": {
        "id": "vRl3bfVgNZ_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan.fit(train_samples, batch_size=64, epochs=10)"
      ],
      "metadata": {
        "id": "BpL8ARH4LpcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = discriminator.predict(test_samples)\n",
        "predictions = pd.Series(data=predictions.reshape((-1)),index=test_samples.index)"
      ],
      "metadata": {
        "id": "G8vbn3waQj9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_fraud = predictions[predictions>0.1].index\n",
        "pred_valid = predictions[predictions<=0.1].index"
      ],
      "metadata": {
        "id": "aoRGQVQITMFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan_fp = (test_labels[pred_fraud]==0).sum()\n",
        "gan_fn = (test_labels[pred_valid]==1).sum()\n",
        "gan_tp = (test_labels==1).sum()\n",
        "gan_tn = (test_labels==0).sum()\n",
        "\n",
        "gan_cm = np.array([[gan_tp - gan_fn, gan_fn],\n",
        "                   [gan_fp, gan_tn - gan_fp]])\n",
        "\n",
        "gan_cm"
      ],
      "metadata": {
        "id": "6tCyVIUpTWgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unsupervised classification with VAEs"
      ],
      "metadata": {
        "id": "C-l3FbXMu2e8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VAE class"
      ],
      "metadata": {
        "id": "ygU64a1Vv5MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE subclassed model\n",
        "\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.sampler = Sampler()\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.total_loss_tracker,\n",
        "                self.reconstruction_loss_tracker,\n",
        "                self.kl_loss_tracker]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of the encoder\n",
        "            z_mean, z_log_var = self.encoder(data)\n",
        "            # Forward pass of the sampler\n",
        "            z = self.sampler(z_mean, z_log_var)\n",
        "            # Forward pass of the decoder\n",
        "            reconstruction = decoder(z)\n",
        "            # Reconstruction loss compares the original image and its reconstructions\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction),\n",
        "                    axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            # KL loss pushes the distribution towards a normal dist. near the origin\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            total_loss = reconstruction_loss + tf.reduce_mean(kl_loss)\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        # Apply gradient descent\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        # Update the metrics\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"total_loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "chi9qy6Bv9b7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VAE model"
      ],
      "metadata": {
        "id": "k84gclQHwBQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 2\n",
        "\n",
        "# encoder\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
        "# Extract abstract features from the input\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "# Map the extracted features to the latent space\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "\n",
        "# Sampling layer which takes sample from the latent space using Gaussian\n",
        "# distribution with mean and variation z_mean and z_log_var.\n",
        "\n",
        "class Sampler(layers.Layer):\n",
        "    def call(self, z_mean, z_log_var):\n",
        "        batch_size = tf.shape(z_mean)[0]\n",
        "        z_size = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.random.normal(shape=(batch_size, z_size))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# decoder\n",
        "\n",
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape((7, 7, 64))(x)\n",
        "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "decoder_outputs = layers.Conv2D(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var], name=\"encoder\")\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")"
      ],
      "metadata": {
        "id": "J-NnAP0au7Ab"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load all the images in the MNIST dataset ignoring the labels\n",
        "\n",
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
        "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLq3gryNwSWv",
        "outputId": "af7e05c9-24e1-4e5e-9b3d-a205637c0a7d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam(), run_eagerly=True)\n",
        "vae.fit(mnist_digits, epochs=30, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "xO2umTsuwbYm",
        "outputId": "0ff2e19b-79c2-4f86-97b6-09acc3ca6295"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "547/547 [==============================] - 37s 50ms/step - total_loss: 207.7602 - reconstruction_loss: 205.3472 - kl_loss: 2.4128\n",
            "Epoch 2/30\n",
            "547/547 [==============================] - 26s 48ms/step - total_loss: 172.7730 - reconstruction_loss: 169.0187 - kl_loss: 3.7544\n",
            "Epoch 3/30\n",
            "547/547 [==============================] - 27s 50ms/step - total_loss: 163.9956 - reconstruction_loss: 160.2668 - kl_loss: 3.7289\n",
            "Epoch 4/30\n",
            "547/547 [==============================] - 26s 47ms/step - total_loss: 159.5737 - reconstruction_loss: 155.7570 - kl_loss: 3.8167\n",
            "Epoch 5/30\n",
            "547/547 [==============================] - 26s 48ms/step - total_loss: 156.7822 - reconstruction_loss: 152.9294 - kl_loss: 3.8528\n",
            "Epoch 6/30\n",
            "547/547 [==============================] - 26s 48ms/step - total_loss: 154.8793 - reconstruction_loss: 151.0452 - kl_loss: 3.8340\n",
            "Epoch 7/30\n",
            "547/547 [==============================] - 54s 98ms/step - total_loss: 153.4983 - reconstruction_loss: 149.6683 - kl_loss: 3.8301\n",
            "Epoch 8/30\n",
            "547/547 [==============================] - 44s 81ms/step - total_loss: 152.6067 - reconstruction_loss: 148.7878 - kl_loss: 3.8190\n",
            "Epoch 9/30\n",
            "547/547 [==============================] - 32s 58ms/step - total_loss: 151.8108 - reconstruction_loss: 147.9928 - kl_loss: 3.8180\n",
            "Epoch 10/30\n",
            " 21/547 [>.............................] - ETA: 25s - total_loss: 151.6614 - reconstruction_loss: 147.9150 - kl_loss: 3.7464"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-db787443114d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_digits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m       \u001b[0mio_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_break\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_distribution = encoder.predict(mnist_digits)"
      ],
      "metadata": {
        "id": "wVPFzIjVxtgG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs = latent_distribution[0][:100,0]\n",
        "ys = latent_distribution[0][:100,1]\n",
        "\n",
        "plt.plot(xs,ys, \"ob\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "snXjlZ3myPUw",
        "outputId": "88e3f2c3-da47-4eb9-8efe-8c16ef1aa6c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xeYvdIJiyTtE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}